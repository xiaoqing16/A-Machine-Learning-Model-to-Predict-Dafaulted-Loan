{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0236a91f",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "Credit risk is one of the risk faced by financial institutions when providing loan service. It is hard to eliminate the risk but finance institutions because of the uncertainty but the risk can reduce through higher interest rates on loans and perform a credit risk assessment before approving loan to minimise the severity of a loss. Machine learning can help to improve the credit risk assessment by create a predictive model using the past data. Hence, Machine Learning plays a vital role in credit risk assessment to help the company in anticipating credit risks.\n",
    "\n",
    "In this problem, a supervised machine learning model will be trained to predict the probability of defaulted loan out of funded loans.\n",
    "\n",
    "\n",
    "Time spent: 42 hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4929323d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f915ce25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings \n",
    "from warnings import filterwarnings\n",
    "filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52076d05",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "58d8e9f9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loanId</th>\n",
       "      <th>anon_ssn</th>\n",
       "      <th>payFrequency</th>\n",
       "      <th>apr</th>\n",
       "      <th>applicationDate</th>\n",
       "      <th>originated</th>\n",
       "      <th>originatedDate</th>\n",
       "      <th>nPaidOff</th>\n",
       "      <th>approved</th>\n",
       "      <th>isFunded</th>\n",
       "      <th>loanStatus</th>\n",
       "      <th>loanAmount</th>\n",
       "      <th>originallyScheduledPaymentAmount</th>\n",
       "      <th>state</th>\n",
       "      <th>leadType</th>\n",
       "      <th>leadCost</th>\n",
       "      <th>fpStatus</th>\n",
       "      <th>clarityFraudId</th>\n",
       "      <th>hasCF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LL-I-07399092</td>\n",
       "      <td>beff4989be82aab4a5b47679216942fd</td>\n",
       "      <td>B</td>\n",
       "      <td>360.0</td>\n",
       "      <td>2016-02-23 17:29:01.940</td>\n",
       "      <td>False</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>Withdrawn Application</td>\n",
       "      <td>500.0</td>\n",
       "      <td>978.27</td>\n",
       "      <td>IL</td>\n",
       "      <td>bvMandatory</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5669ef78e4b0c9d3936440e6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LL-I-06644937</td>\n",
       "      <td>464f5d9ae4fa09ece4048d949191865c</td>\n",
       "      <td>B</td>\n",
       "      <td>199.0</td>\n",
       "      <td>2016-01-19 22:07:36.778</td>\n",
       "      <td>True</td>\n",
       "      <td>2016-01-20 15:49:18.846</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>Paid Off Loan</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>6395.19</td>\n",
       "      <td>CA</td>\n",
       "      <td>prescreen</td>\n",
       "      <td>0</td>\n",
       "      <td>Checked</td>\n",
       "      <td>569eb3a3e4b096699f685d64</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LL-I-10707532</td>\n",
       "      <td>3c174ae9e2505a5f9ddbff9843281845</td>\n",
       "      <td>B</td>\n",
       "      <td>590.0</td>\n",
       "      <td>2016-08-01 13:51:14.709</td>\n",
       "      <td>False</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>Withdrawn Application</td>\n",
       "      <td>400.0</td>\n",
       "      <td>1199.45</td>\n",
       "      <td>MO</td>\n",
       "      <td>bvMandatory</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>579eab11e4b0d0502870ef2f</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LL-I-02272596</td>\n",
       "      <td>9be6f443bb97db7e95fa0c281d34da91</td>\n",
       "      <td>B</td>\n",
       "      <td>360.0</td>\n",
       "      <td>2015-08-06 23:58:08.880</td>\n",
       "      <td>False</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>Withdrawn Application</td>\n",
       "      <td>500.0</td>\n",
       "      <td>1074.05</td>\n",
       "      <td>IL</td>\n",
       "      <td>bvMandatory</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>555b1e95e4b0f6f11b267c18</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LL-I-09542882</td>\n",
       "      <td>63b5494f60b5c19c827c7b068443752c</td>\n",
       "      <td>B</td>\n",
       "      <td>590.0</td>\n",
       "      <td>2016-06-05 22:31:34.304</td>\n",
       "      <td>False</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>Rejected</td>\n",
       "      <td>350.0</td>\n",
       "      <td>814.37</td>\n",
       "      <td>NV</td>\n",
       "      <td>bvMandatory</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5754a91be4b0c6a2bf424772</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          loanId                          anon_ssn payFrequency    apr  \\\n",
       "0  LL-I-07399092  beff4989be82aab4a5b47679216942fd            B  360.0   \n",
       "1  LL-I-06644937  464f5d9ae4fa09ece4048d949191865c            B  199.0   \n",
       "2  LL-I-10707532  3c174ae9e2505a5f9ddbff9843281845            B  590.0   \n",
       "3  LL-I-02272596  9be6f443bb97db7e95fa0c281d34da91            B  360.0   \n",
       "4  LL-I-09542882  63b5494f60b5c19c827c7b068443752c            B  590.0   \n",
       "\n",
       "          applicationDate  originated          originatedDate  nPaidOff  \\\n",
       "0 2016-02-23 17:29:01.940       False                     NaT       0.0   \n",
       "1 2016-01-19 22:07:36.778        True 2016-01-20 15:49:18.846       0.0   \n",
       "2 2016-08-01 13:51:14.709       False                     NaT       0.0   \n",
       "3 2015-08-06 23:58:08.880       False                     NaT       0.0   \n",
       "4 2016-06-05 22:31:34.304       False                     NaT       0.0   \n",
       "\n",
       "   approved  isFunded             loanStatus  loanAmount  \\\n",
       "0     False         0  Withdrawn Application       500.0   \n",
       "1      True         1          Paid Off Loan      3000.0   \n",
       "2     False         0  Withdrawn Application       400.0   \n",
       "3     False         0  Withdrawn Application       500.0   \n",
       "4     False         0               Rejected       350.0   \n",
       "\n",
       "   originallyScheduledPaymentAmount state     leadType  leadCost fpStatus  \\\n",
       "0                            978.27    IL  bvMandatory         6      NaN   \n",
       "1                           6395.19    CA    prescreen         0  Checked   \n",
       "2                           1199.45    MO  bvMandatory         3      NaN   \n",
       "3                           1074.05    IL  bvMandatory         3      NaN   \n",
       "4                            814.37    NV  bvMandatory         3      NaN   \n",
       "\n",
       "             clarityFraudId  hasCF  \n",
       "0  5669ef78e4b0c9d3936440e6      1  \n",
       "1  569eb3a3e4b096699f685d64      1  \n",
       "2  579eab11e4b0d0502870ef2f      1  \n",
       "3  555b1e95e4b0f6f11b267c18      1  \n",
       "4  5754a91be4b0c6a2bf424772      1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import data\n",
    "data = pd.read_csv(r\"C:\\Users\\User\\Desktop\\Online Course\\Moneylion\\data\\loan.csv\", parse_dates=['applicationDate','originatedDate'])\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c97aece5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 38982 entries, 1 to 577662\n",
      "Data columns (total 19 columns):\n",
      " #   Column                            Non-Null Count  Dtype         \n",
      "---  ------                            --------------  -----         \n",
      " 0   loanId                            38982 non-null  object        \n",
      " 1   anon_ssn                          38982 non-null  object        \n",
      " 2   payFrequency                      38982 non-null  object        \n",
      " 3   apr                               38982 non-null  float64       \n",
      " 4   applicationDate                   38982 non-null  datetime64[ns]\n",
      " 5   originated                        38982 non-null  bool          \n",
      " 6   originatedDate                    38982 non-null  datetime64[ns]\n",
      " 7   nPaidOff                          38961 non-null  float64       \n",
      " 8   approved                          38982 non-null  bool          \n",
      " 9   isFunded                          38982 non-null  int64         \n",
      " 10  loanStatus                        38982 non-null  object        \n",
      " 11  loanAmount                        38982 non-null  float64       \n",
      " 12  originallyScheduledPaymentAmount  38982 non-null  float64       \n",
      " 13  state                             38982 non-null  object        \n",
      " 14  leadType                          38982 non-null  object        \n",
      " 15  leadCost                          38982 non-null  int64         \n",
      " 16  fpStatus                          38973 non-null  object        \n",
      " 17  clarityFraudId                    32360 non-null  object        \n",
      " 18  hasCF                             38982 non-null  int64         \n",
      "dtypes: bool(2), datetime64[ns](2), float64(4), int64(3), object(8)\n",
      "memory usage: 5.4+ MB\n"
     ]
    }
   ],
   "source": [
    "# Remove unfunded loan\n",
    "data = data[data['isFunded'].eq(1)]\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bc783c62",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "loanId                                 0\n",
       "anon_ssn                               0\n",
       "payFrequency                           0\n",
       "apr                                    0\n",
       "applicationDate                        0\n",
       "originated                             0\n",
       "originatedDate                         0\n",
       "nPaidOff                              21\n",
       "approved                               0\n",
       "isFunded                               0\n",
       "loanStatus                             0\n",
       "loanAmount                             0\n",
       "originallyScheduledPaymentAmount       0\n",
       "state                                  0\n",
       "leadType                               0\n",
       "leadCost                               0\n",
       "fpStatus                               9\n",
       "clarityFraudId                      6622\n",
       "hasCF                                  0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count the missing value in every column\n",
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85888f9a",
   "metadata": {},
   "source": [
    "Just drop the missing values of `nPaidOff` since there is only 21 missing values out of 38983 data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "03f5883b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 38961 entries, 1 to 577662\n",
      "Data columns (total 19 columns):\n",
      " #   Column                            Non-Null Count  Dtype         \n",
      "---  ------                            --------------  -----         \n",
      " 0   loanId                            38961 non-null  object        \n",
      " 1   anon_ssn                          38961 non-null  object        \n",
      " 2   payFrequency                      38961 non-null  object        \n",
      " 3   apr                               38961 non-null  float64       \n",
      " 4   applicationDate                   38961 non-null  datetime64[ns]\n",
      " 5   originated                        38961 non-null  bool          \n",
      " 6   originatedDate                    38961 non-null  datetime64[ns]\n",
      " 7   nPaidOff                          38961 non-null  float64       \n",
      " 8   approved                          38961 non-null  bool          \n",
      " 9   isFunded                          38961 non-null  int64         \n",
      " 10  loanStatus                        38961 non-null  object        \n",
      " 11  loanAmount                        38961 non-null  float64       \n",
      " 12  originallyScheduledPaymentAmount  38961 non-null  float64       \n",
      " 13  state                             38961 non-null  object        \n",
      " 14  leadType                          38961 non-null  object        \n",
      " 15  leadCost                          38961 non-null  int64         \n",
      " 16  fpStatus                          38952 non-null  object        \n",
      " 17  clarityFraudId                    32358 non-null  object        \n",
      " 18  hasCF                             38961 non-null  int64         \n",
      "dtypes: bool(2), datetime64[ns](2), float64(4), int64(3), object(8)\n",
      "memory usage: 5.4+ MB\n"
     ]
    }
   ],
   "source": [
    "data = data[data['nPaidOff'].notna()]\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3887e19c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Paid Off Loan                  0.293165\n",
       "External Collection            0.290547\n",
       "New Loan                       0.208208\n",
       "Internal Collection            0.142809\n",
       "Returned Item                  0.030338\n",
       "Settlement Paid Off            0.018121\n",
       "Settled Bankruptcy             0.008342\n",
       "Pending Paid Off               0.004338\n",
       "Charged Off Paid Off           0.004081\n",
       "Settlement Pending Paid Off    0.000026\n",
       "Charged Off                    0.000026\n",
       "Name: loanStatus, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get percentage count of loanStatus\n",
    "data['loanStatus'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98c7abac",
   "metadata": {},
   "source": [
    "### Create a new label variable\n",
    "The label variable of this problem is `loanStatus`. Before using it, the data need to convert categorical form. But some of the values of loanStatus are lack of information. Hence, only the values seem self-explanatory will be used to create the new label variable.\n",
    "\n",
    "The data will convert into two classes:\n",
    "- Class 0: if the loan was paid\n",
    "- Class 1: if the load was defaulted\n",
    "\n",
    "For Class 0, only the following values will be considering:\n",
    "- Paid Off Loan\n",
    "- Settlement Paid Off\n",
    "\n",
    "For Class 1, only the following values will be considering:\n",
    "- Settled Bankruptcy\n",
    "- Charged Off\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0646a0b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save labels\n",
    "labels = {1: ['Settled Bankruptcy','Charged Off'], \n",
    "          0:['Paid Off Loan','Settlement Paid Off']}\n",
    "\n",
    "# Map labels\n",
    "def map_label(data):\n",
    "    for column,item in labels.items():\n",
    "        if data in item:\n",
    "            return column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "685eb212",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 12454 entries, 0 to 12453\n",
      "Data columns (total 20 columns):\n",
      " #   Column                            Non-Null Count  Dtype         \n",
      "---  ------                            --------------  -----         \n",
      " 0   loanId                            12454 non-null  object        \n",
      " 1   anon_ssn                          12454 non-null  object        \n",
      " 2   payFrequency                      12454 non-null  object        \n",
      " 3   apr                               12454 non-null  float64       \n",
      " 4   applicationDate                   12454 non-null  datetime64[ns]\n",
      " 5   originated                        12454 non-null  bool          \n",
      " 6   originatedDate                    12454 non-null  datetime64[ns]\n",
      " 7   nPaidOff                          12454 non-null  float64       \n",
      " 8   approved                          12454 non-null  bool          \n",
      " 9   isFunded                          12454 non-null  int64         \n",
      " 10  loanStatus                        12454 non-null  object        \n",
      " 11  loanAmount                        12454 non-null  float64       \n",
      " 12  originallyScheduledPaymentAmount  12454 non-null  float64       \n",
      " 13  state                             12454 non-null  object        \n",
      " 14  leadType                          12454 non-null  object        \n",
      " 15  leadCost                          12454 non-null  int64         \n",
      " 16  fpStatus                          12454 non-null  object        \n",
      " 17  clarityFraudId                    9917 non-null   object        \n",
      " 18  hasCF                             12454 non-null  int64         \n",
      " 19  isDefault                         12454 non-null  int32         \n",
      "dtypes: bool(2), datetime64[ns](2), float64(4), int32(1), int64(3), object(8)\n",
      "memory usage: 1.7+ MB\n"
     ]
    }
   ],
   "source": [
    "data['isDefault'] = data['loanStatus'].map(map_label)\n",
    "trainData = data[data['isDefault'].notna()].reset_index(drop=True)\n",
    "trainData['isDefault'] = trainData['isDefault'].astype(int)\n",
    "trainData.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d543d571",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.973824\n",
       "1    0.026176\n",
       "Name: isDefault, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get percentage count of new label variable\n",
    "trainData['isDefault'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e09a8a2",
   "metadata": {},
   "source": [
    "The dataset is imblanced since most of the data is under Class 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f485dd6",
   "metadata": {},
   "source": [
    "## Data Exploration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6e122c64",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "applicationDate\n",
      "----------------------------------------------------------------------------------------------------\n",
      "           count unique                     top freq                   first  \\\n",
      "isDefault                                                                      \n",
      "0          12128  12127 2015-02-20 17:16:24.718    2 2014-12-04 21:30:27.564   \n",
      "1            326    326 2017-01-11 08:54:04.639    1 2015-02-13 18:35:34.286   \n",
      "\n",
      "                             last  \n",
      "isDefault                          \n",
      "0         2017-03-18 23:34:27.369  \n",
      "1         2017-03-17 20:49:59.334  \n",
      "****************************************************************************************************\n",
      "approved\n",
      "----------------------------------------------------------------------------------------------------\n",
      "           count unique   top   freq\n",
      "isDefault                           \n",
      "0          12128      1  True  12128\n",
      "1            326      1  True    326\n",
      "****************************************************************************************************\n",
      "apr\n",
      "----------------------------------------------------------------------------------------------------\n",
      "             count        mean         std    min    25%    50%    75%    95%  \\\n",
      "isDefault                                                                       \n",
      "0          12128.0  509.817574  116.917889    0.0  390.0  565.0  590.0  650.0   \n",
      "1            326.0  481.325661  121.219038  159.0  360.0  495.0  590.0  625.0   \n",
      "\n",
      "             99%     max  \n",
      "isDefault                 \n",
      "0          681.0  705.59  \n",
      "1          672.5  681.00  \n",
      "****************************************************************************************************\n",
      "fpStatus\n",
      "----------------------------------------------------------------------------------------------------\n",
      "fpStatus   Cancelled   Checked  Rejected   Skipped\n",
      "isDefault                                         \n",
      "0           0.016821  0.953496  0.024901  0.004782\n",
      "1           0.012270  0.825153  0.144172  0.018405\n",
      "hasCF\n",
      "----------------------------------------------------------------------------------------------------\n",
      "             count      mean       std  min  25%  50%  75%  95%  99%  max\n",
      "isDefault                                                                \n",
      "0          12128.0  0.794278  0.404245  0.0  1.0  1.0  1.0  1.0  1.0  1.0\n",
      "1            326.0  0.871166  0.335532  0.0  1.0  1.0  1.0  1.0  1.0  1.0\n",
      "****************************************************************************************************\n",
      "isDefault\n",
      "----------------------------------------------------------------------------------------------------\n",
      "             count  mean  std  min  25%  50%  75%  95%  99%  max\n",
      "isDefault                                                       \n",
      "0          12128.0   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
      "1            326.0   1.0  0.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0\n",
      "****************************************************************************************************\n",
      "isFunded\n",
      "----------------------------------------------------------------------------------------------------\n",
      "             count  mean  std  min  25%  50%  75%  95%  99%  max\n",
      "isDefault                                                       \n",
      "0          12128.0   1.0  0.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0\n",
      "1            326.0   1.0  0.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0\n",
      "****************************************************************************************************\n",
      "leadCost\n",
      "----------------------------------------------------------------------------------------------------\n",
      "             count       mean        std  min  25%  50%   75%   95%    99%  \\\n",
      "isDefault                                                                    \n",
      "0          12128.0  12.039578  24.735985  0.0  0.0  3.0  10.0  60.0  100.0   \n",
      "1            326.0  14.677914  25.345076  0.0  0.0  4.5  10.0  75.0  115.0   \n",
      "\n",
      "             max  \n",
      "isDefault         \n",
      "0          200.0  \n",
      "1          200.0  \n",
      "****************************************************************************************************\n",
      "leadType\n",
      "----------------------------------------------------------------------------------------------------\n",
      "leadType   bvMandatory  california   express  instant-offer      lead  \\\n",
      "isDefault                                                               \n",
      "0             0.388687    0.002061  0.000742       0.000082  0.221059   \n",
      "1             0.460123    0.003067       NaN            NaN  0.266871   \n",
      "\n",
      "leadType    lionpay   organic  prescreen  rc_returning    repeat  \n",
      "isDefault                                                         \n",
      "0          0.000577  0.292134   0.042051      0.052111  0.000495  \n",
      "1               NaN  0.205521   0.055215      0.009202       NaN  \n",
      "loanAmount\n",
      "----------------------------------------------------------------------------------------------------\n",
      "             count        mean         std    min    25%    50%    75%  \\\n",
      "isDefault                                                                \n",
      "0          12128.0  628.201517  450.900162  100.0  350.0  500.0  700.0   \n",
      "1            326.0  668.668712  485.565308  200.0  400.0  500.0  800.0   \n",
      "\n",
      "              95%     99%     max  \n",
      "isDefault                          \n",
      "0          1500.0  3000.0  4687.0  \n",
      "1          1500.0  2912.5  3000.0  \n",
      "****************************************************************************************************\n",
      "loanStatus\n",
      "----------------------------------------------------------------------------------------------------\n",
      "loanStatus  Charged Off  Paid Off Loan  Settled Bankruptcy  \\\n",
      "isDefault                                                    \n",
      "0                   NaN       0.941788                 NaN   \n",
      "1              0.003067            NaN            0.996933   \n",
      "\n",
      "loanStatus  Settlement Paid Off  \n",
      "isDefault                        \n",
      "0                      0.058212  \n",
      "1                           NaN  \n",
      "nPaidOff\n",
      "----------------------------------------------------------------------------------------------------\n",
      "             count      mean       std  min  25%  50%  75%  95%   99%   max\n",
      "isDefault                                                                  \n",
      "0          12128.0  0.597460  1.401998  0.0  0.0  0.0  1.0  3.0  6.00  21.0\n",
      "1            326.0  0.328221  0.788144  0.0  0.0  0.0  0.0  2.0  3.75   6.0\n",
      "****************************************************************************************************\n",
      "originallyScheduledPaymentAmount\n",
      "----------------------------------------------------------------------------------------------------\n",
      "             count         mean          std     min       25%       50%  \\\n",
      "isDefault                                                                  \n",
      "0          12128.0  1660.526528  1201.018749  188.41  949.4675  1303.620   \n",
      "1            326.0  1713.532853  1278.321699  481.95  995.0550  1327.195   \n",
      "\n",
      "                 75%        95%        99%       max  \n",
      "isDefault                                             \n",
      "0          1942.8325  3624.3900  6814.8118  12550.08  \n",
      "1          1974.0100  3995.0125  6901.1975   9380.70  \n",
      "****************************************************************************************************\n",
      "originated\n",
      "----------------------------------------------------------------------------------------------------\n",
      "           count unique   top   freq\n",
      "isDefault                           \n",
      "0          12128      1  True  12128\n",
      "1            326      1  True    326\n",
      "****************************************************************************************************\n",
      "originatedDate\n",
      "----------------------------------------------------------------------------------------------------\n",
      "           count unique                     top freq                   first  \\\n",
      "isDefault                                                                      \n",
      "0          12128  12127 2015-02-20 19:40:33.329    2 2014-12-05 15:28:07.491   \n",
      "1            326    326 2016-12-02 16:47:00.207    1 2015-04-07 19:06:12.290   \n",
      "\n",
      "                             last  \n",
      "isDefault                          \n",
      "0         2017-03-23 22:51:38.921  \n",
      "1         2017-03-17 21:00:25.361  \n",
      "****************************************************************************************************\n",
      "payFrequency\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "payFrequency         B         I         M         S         W\n",
      "isDefault                                                     \n",
      "0             0.588473  0.024241  0.078001  0.058212  0.251072\n",
      "1             0.622699  0.021472  0.042945  0.067485  0.245399\n",
      "state\n",
      "----------------------------------------------------------------------------------------------------\n",
      "state            AL        AZ        CA        CO        CT        DE  \\\n",
      "isDefault                                                               \n",
      "0          0.003133  0.011131  0.035125  0.001979  0.007338  0.000907   \n",
      "1               NaN  0.006135  0.049080       NaN       NaN       NaN   \n",
      "\n",
      "state            FL        GA        HI        IA  ...        RI        SC  \\\n",
      "isDefault                                          ...                       \n",
      "0          0.029601  0.001649  0.000742  0.001732  ...  0.000825  0.023087   \n",
      "1               NaN       NaN       NaN       NaN  ...       NaN  0.006135   \n",
      "\n",
      "state            SD        TN        TX        UT        VA      WA        WI  \\\n",
      "isDefault                                                                       \n",
      "0          0.002226  0.031497  0.056151  0.004123  0.007009  0.0047  0.099192   \n",
      "1               NaN  0.061350  0.024540  0.015337  0.012270     NaN  0.101227   \n",
      "\n",
      "state            WY  \n",
      "isDefault            \n",
      "0          0.002226  \n",
      "1               NaN  \n",
      "\n",
      "[2 rows x 40 columns]\n"
     ]
    }
   ],
   "source": [
    "#list statistics of all features except loanId, clarityFraudId and anon_ssn\n",
    "vars = ['loanId','clarityFraudId','anon_ssn']\n",
    "for x in trainData.columns.difference(vars):\n",
    "    print(x)\n",
    "    print('-'*100)\n",
    "    if trainData[x].dtype != 'object':\n",
    "        print(trainData.groupby('isDefault')[x].describe(percentiles=[.25,.5,.75,.95,.99]))\n",
    "        print('*'*100)\n",
    "    else:\n",
    "        print(trainData.groupby('isDefault')[x].value_counts(normalize=True, ascending=False, sort=True).unstack())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dfc9576",
   "metadata": {},
   "source": [
    "There is few information can understand from the statistics:\n",
    "1. 14% of defaulted loan is rejected for first payment which means the payment of loan was unsuccessful. For paid loan, there are only 2% of loan is rejected for first payment.\n",
    "2. 46% of defaulted loan has a `byMandatory` lead type which means bank\tverification had performed before loan approval.\n",
    "3. 5.5% of defaulted loan is from preselected customers who have been offered a loan through direct mail campaigns.\n",
    "4. Only 0.9% of defaulted loan is come from customers who have at least\t1\tpaid off loan in another loan portfolio where 5 % of paid loan come from customers who have at least 1 paid off loan.\n",
    "5. The `leadCost` of defaulted loan has higher mean than the `leadCost` of pain loan.\n",
    "6. Customers have defaulted loan have a lower mean of `nPaidOff` compared with customer have paid loan.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22b6dc64",
   "metadata": {},
   "source": [
    "### Merge with clarityfraud data\n",
    "\n",
    "Use the `clearfraudscore` from **clarityfraud** data to provide more information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "17b0c3a5",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:\\\\Users\\\\User\\\\Desktop\\\\Moneylion\\\\data\\\\clarity_underwriting_variables.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-00afd0919fd4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mclarityFraud\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mr\"C:\\Users\\User\\Desktop\\Moneylion\\data\\clarity_underwriting_variables.csv\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mclarityFraud\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    608\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    609\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 610\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    611\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    612\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    460\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    461\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 462\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    463\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    464\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    817\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    818\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 819\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    820\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    821\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1048\u001b[0m             )\n\u001b[0;32m   1049\u001b[0m         \u001b[1;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1050\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[call-arg]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1051\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1052\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1865\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1866\u001b[0m         \u001b[1;31m# open handles\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1867\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1868\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1869\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"storage_options\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"encoding\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"memory_map\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"compression\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_open_handles\u001b[1;34m(self, src, kwds)\u001b[0m\n\u001b[0;32m   1360\u001b[0m         \u001b[0mLet\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mreaders\u001b[0m \u001b[0mopen\u001b[0m \u001b[0mIOHanldes\u001b[0m \u001b[0mafter\u001b[0m \u001b[0mthey\u001b[0m \u001b[0mare\u001b[0m \u001b[0mdone\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mtheir\u001b[0m \u001b[0mpotential\u001b[0m \u001b[0mraises\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1361\u001b[0m         \"\"\"\n\u001b[1;32m-> 1362\u001b[1;33m         self.handles = get_handle(\n\u001b[0m\u001b[0;32m   1363\u001b[0m             \u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1364\u001b[0m             \u001b[1;34m\"r\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    640\u001b[0m                 \u001b[0merrors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"replace\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    641\u001b[0m             \u001b[1;31m# Encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 642\u001b[1;33m             handle = open(\n\u001b[0m\u001b[0;32m    643\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    644\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:\\\\Users\\\\User\\\\Desktop\\\\Moneylion\\\\data\\\\clarity_underwriting_variables.csv'"
     ]
    }
   ],
   "source": [
    "clarityFraud = pd.read_csv(r\"C:\\Users\\User\\Desktop\\Moneylion\\data\\clarity_underwriting_variables.csv\")\n",
    "clarityFraud.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cf93a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainData = trainData.merge(clarityFraud[['underwritingid','clearfraudscore']], \n",
    "                    left_on='clarityFraudId', \n",
    "                    right_on='underwritingid', \n",
    "                    how='left')\n",
    "trainData.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18ef2787",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#visualise clearfraudscore\n",
    "sns.distplot(trainData.loc[trainData['clearfraudscore'].notna(), 'clearfraudscore'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8bfe0c2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.boxplot(x = 'isDefault',\n",
    "            y=\"clearfraudscore\",\n",
    "            data=trainData.loc[trainData['clearfraudscore'].notna()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "665842a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 6))\n",
    "sns.boxplot(x=\"nPaidOff\", y=\"clearfraudscore\",\n",
    "            hue=\"isDefault\", palette=[\"m\", \"g\"],\n",
    "            data=trainData[trainData['clearfraudscore'].notna()])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a21aae8",
   "metadata": {},
   "source": [
    "The first graph showed that `clearfraudscore` is a left skewed variable. Besides that, the defaulted loan has higher minimum value for fraud score compared with paid loan which shown in the second graph. Lastly, the `nPaidOff` of defaulted loan are less than 4 times but paid loan has the `nPaidOff` up to 13 times."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ae19280",
   "metadata": {},
   "source": [
    "## Feature Engineering\n",
    "\n",
    "After exploring the data, few new variables need to create to transform raw data into features that better represent the underlying problem to the predictive models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50cb9a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count Loan by using SSN\n",
    "trainData['countLoan'] = trainData['anon_ssn'].map(trainData.groupby('anon_ssn')['loanId'].count()).astype(int)\n",
    "trainData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42bc28bc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.boxplot(x = 'isDefault',\n",
    "            y=\"countLoan\",\n",
    "            data=trainData)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "712b878f",
   "metadata": {},
   "source": [
    "The box plot shows that the `countLoan` between two classes have very big difference. Class 0 have higher `countLoan` compared to Class 1. The defaulted loans motsly come from new customers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "953b3b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# count past paid loan by client\n",
    "trainData['countPaidOff'] = trainData['anon_ssn'].map(data.groupby('anon_ssn')['nPaidOff'].sum()).astype(int)\n",
    "trainData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31f0cb07",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x = 'isDefault',\n",
    "            y=\"countPaidOff\",\n",
    "            data=trainData)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a307c411",
   "metadata": {},
   "source": [
    "Class 0 has higher `countPaidOff` than class 1 which means paid off loans are mostly come fron existing customers. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fbc43c3",
   "metadata": {},
   "source": [
    "### Merge data from payment \n",
    "\n",
    "The `paymentStatus` from **payment** data will be merged to count the occurence of `paymentStatus` for each `loanId`. This can helps us to understand about the payment history for each loan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7422a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "payment = pd.read_csv(r\"C:\\Users\\User\\Desktop\\Moneylion\\data\\payment.csv\", parse_dates=['paymentDate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d89d078c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Occurence of paymentStatus for each loanId\n",
    "payment['val'] = 1\n",
    "\n",
    "countPayment = (payment\n",
    " .pivot_table(index=['loanId'], columns=['paymentStatus'], values='val', aggfunc=sum, fill_value=0)\n",
    " .reset_index())\n",
    "\n",
    "print(countPayment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "786cecc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainData = (trainData.merge(countPayment, on='loanId', how='left')\n",
    "         .drop(['loanId'], axis=1))\n",
    "trainData.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc9f46c6",
   "metadata": {},
   "source": [
    "### Encoding Categorical Variables\n",
    "Most of the models can only read nummeric variables. Hence, string values need to encode into numeric values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93722340",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import library\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4f49e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "var = ['payFrequency','leadType','fpStatus','state']\n",
    "\n",
    "unused_var = ['clarityFraudId','underwritingid','originated','approved','isFunded','loanStatus','applicationDate','originatedDate','anon_ssn']\n",
    "\n",
    "#encode categorical data uring Label Encoder then save to a new variable\n",
    "for i in var:\n",
    "    lbl = LabelEncoder()\n",
    "    trainData[i + '_en'] = lbl.fit_transform(trainData[i])\n",
    "\n",
    "# drop the variables that are no information \n",
    "trainData = trainData.drop(var + unused_var, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efafcc76",
   "metadata": {},
   "source": [
    "## Modeling\n",
    "\n",
    "After preprocessing the data, the dataset is ready to train a machine learning model. **Gradient Boosted Decision Trees** will be used as the classifier because of the following reason:\n",
    "1. Robust to outliers\n",
    "2. Robust to skewness\n",
    "3. Robust to null value\n",
    "4. Better accuracy than any other boosting algorithm\n",
    "5. Faster training speed and higher efficiency\n",
    "\n",
    "AUC will be used to evaluate the model performance because:\n",
    "1. AUC is a better performance metric than accuracy\n",
    "2. AUC does not bias on size of test or evaluation data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87c668ff",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import libraries\n",
    "from sklearn.model_selection import train_test_split\n",
    "import lightgbm as lgb "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26b9a216",
   "metadata": {},
   "source": [
    "Split dataset into 70-30 where 70% of the data is training set and 30% of the data is testing set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "463d81bf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "label = trainData['isDefault']\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(trainData, label, test_size=0.3,stratify = label)\n",
    "\n",
    "X_train = X_train.drop(['isDefault'], axis=1)\n",
    "X_valid = X_valid.drop(['isDefault'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d95073ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#construct lgb dataset\n",
    "train = lgb.Dataset(X_train.values,\n",
    "                           label=y_train.values)\n",
    "valid = lgb.Dataset(X_valid.values,\n",
    "                       label=y_valid.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5aab0fe",
   "metadata": {},
   "source": [
    "After trying out with different number, the tuning parameter is shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e0ab1eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#parameter tuning\n",
    "params = {\n",
    "    'num_leaves': 19,\n",
    "     'max_bin': 55,\n",
    "     'min_data_in_leaf': 5,\n",
    "     'learning_rate': 0.01,\n",
    "     'min_sum_hessian_in_leaf': 0.009,\n",
    "     'feature_fraction': 0.05,\n",
    "     'min_gain_to_split': 0.45,\n",
    "     'max_depth': 3,\n",
    "     'save_binary': True,\n",
    "     'objective': 'binary',\n",
    "     'boosting_type': 'gbdt',\n",
    "     'metric': 'auc',\n",
    "     'is_unbalance': True,\n",
    "     'boost_from_average': False\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d22cda61",
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepare model\n",
    "model = lgb.train(params,train,\n",
    "                1500, \n",
    "                valid_sets = [train, valid], \n",
    "                verbose_eval=100,\n",
    "                early_stopping_rounds=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53ba26f5",
   "metadata": {},
   "source": [
    "The AUC of the model is **0.88** which is high but the model is likely overfitting because the training's AUC is higher than testing's AUC. Now, the feature importance will be plotted to determine what feature is not important then remove it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec148ea3",
   "metadata": {},
   "source": [
    "### Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac3b3fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "featureImportance = pd.DataFrame(sorted(zip(model.feature_importance(),X_train.columns)), columns=['Value','Features'])\n",
    "\n",
    "sns.barplot(x=\"Value\", y=\"Features\", data=featureImportance.sort_values(by=\"Value\", ascending=False))\n",
    "plt.title('Feature Importance based on the trained model')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59af0235",
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove features there are less important\n",
    "unwant_feat = ['Rejected Awaiting Retry','state_en','hasCF','Returned','Complete']\n",
    "trainData = trainData.drop(unwant_feat, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21d7c2f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the dataset again\n",
    "label = trainData['isDefault']\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(trainData, label, test_size=0.3,stratify = label)\n",
    "\n",
    "X_train = X_train.drop(['isDefault'], axis=1)\n",
    "X_valid = X_valid.drop(['isDefault'], axis=1)\n",
    "train = lgb.Dataset(X_train.values,\n",
    "                           label=y_train.values)\n",
    "valid = lgb.Dataset(X_valid.values,\n",
    "                       label=y_valid.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8885388a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prepare a new model\n",
    "new_model = lgb.train(params,train,\n",
    "                1500, \n",
    "                valid_sets = [train, valid], \n",
    "                verbose_eval=100,\n",
    "                early_stopping_rounds=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "108c57ae",
   "metadata": {},
   "source": [
    "After remove some features, the AUC of the model has increased to **0.93** but the model still overfitting. \n",
    "\n",
    "# Future Plan\n",
    "There are few problems facing by model. First, the model is overfitting which means the the model performs well on training data but generalizes poorly to unseen data. Hence few steps can be taken to solve the problem.\n",
    "\n",
    "Steps to handle overfitting\n",
    "1. The model needs to train with more data. Because the current dataset is imbalanced. Only 2.6% of data is under the defaulted loan category. Hence, the model is may not able to classify the data very well.\n",
    "2. Implement Cross-Validation on training set. we may use initial training data to generate multiple mini train-test splits. Then, use these splits to tune the model. This method can tune hyperparameters with initial training set to keep the test set as a truly unseen dataset for selecting final model.\n",
    "3. Feature Selection. After training more data, maybe we can do the feature selection again. That is because the current feature importance is based on the model and it may be not accuracy due to the imbalance data.\n",
    "4. Feature Engineering. Try to transform more raw data like date data into features to gain more information on the dataset. Because the current features may not enough to build a good model.\n",
    "5. Try with other machine learning algorithms. Other machine learning algorithms may be work better with the current one. Hence, we may to play with other machine learning algorithms to compare the performance with current one to find out which is the best algorithm for the case.\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
